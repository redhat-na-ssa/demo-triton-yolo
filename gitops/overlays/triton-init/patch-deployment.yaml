- op: add
  path: /spec/template/spec/initContainers
  value:
    - name: get-model
      env:
        - name: MODEL_NAME
          value: yolov8n
        - name: HOME
          value: /tmp
      command:
        - bash
        - -c
        - |
          #/bin/sh
          # set -x

          debug(){
            echo "
              This process is runing as $(id)
              Path: $(pwd)
            "
            # [ -d /tmp/src ] && ls -lRh /tmp/src 
            # ls -lRh

            which pip >/dev/null 2>&1 || return 0
            pip list 
          }

          build_config_pbtxt_cpu(){
            MODEL_NAME=${1:-yolov8n}
            IMG_X=${2:-640}
            IMG_Y=${3}

          [ -d "${MODEL_NAME}/1" ] || mkdir -p "${MODEL_NAME}/1"

          cat <<CONFIG > "${MODEL_NAME}/config.pbtxt"

          name: "${MODEL_NAME}"
          default_model_filename:"${MODEL_NAME}.onnx"
          platform: "onnxruntime_onnx"
          # max_batch_size: 0

          input [
            {
              name: "images"
              data_type: TYPE_FP32
              dims: [ 1, 3, ${IMG_X}, ${IMG_Y:-${IMG_X}} ]
            }
          ]
          output [
            {
              name: "output0"
              data_type: TYPE_FP32
              dims: [ 1, 84, 8400 ]
            }
          ]
          model_warmup [
            {
              name: "zero_input"
              # batch_size: 1
              inputs: {
                key: "images"
                value: {
                  data_type: TYPE_FP32
                  dims: [1, 3, 640, 640]
                  zero_data: true
                }
              }
            }
          ]
          CONFIG
          }

          build_config_pbtxt_gpu(){
            MODEL_NAME=${1:-yolo11n}
            IMG_X=${2:-640}
            IMG_Y=${3}

          [ -d "${MODEL_NAME}/1" ] || mkdir -p "${MODEL_NAME}/1"

          cat <<CONFIG > "${MODEL_NAME}/config.pbtxt"
          name: "${MODEL_NAME}"
          default_model_filename:"${MODEL_NAME}.onnx"
          optimization {
            execution_accelerators {
              gpu_execution_accelerator {
                name: "tensorrt"
                parameters {
                  key: "precision_mode"
                  value: "FP16"
                }
                parameters {
                  key: "max_workspace_size_bytes"
                  value: "3221225472"
                }
                parameters {
                  key: "trt_engine_cache_enable"
                  value: "1"
                }
                parameters {
                  key: "trt_engine_cache_path"
                  value: "/models/${MODEL_NAME}/1"
                }
              }
            }
          }
          CONFIG
          }

          get_model(){
            MODEL_NAME=${1:-yolov8n}
            IMG_X=${2:-640}
            IMG_Y=${3}
            
            # download model with cli
            echo "MODEL_NAME: ${MODEL_NAME}"
            yolo export model="${MODEL_NAME}.pt" imgsz="${IMG_X},${IMG_Y}" format=onnx

            # create triton config.pbtxt
            build_config_pbtxt_gpu "${MODEL_NAME}" "${IMG_X}" "${IMG_Y}"

            # copy model
            mv "${MODEL_NAME}.onnx" "${MODEL_NAME}/1/"
            mv "${MODEL_NAME}" /models
          }

          cd /tmp
          get_model ${MODEL_NAME} || debug

      image: docker.io/ultralytics/ultralytics:latest-cpu
      volumeMounts:
        - mountPath: /models
          name: models
          subPath: cache
      resources:
        limits:
          cpu: 500m
          memory: 1Gi
